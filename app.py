import streamlit as st
import pandas as pd
import pdfplumber
import docx
import os
import json
from io import BytesIO
from dotenv import load_dotenv
from openai import OpenAI

# =========================
# CONFIG
# =========================
st.set_page_config(
    page_title="Tr·ª£ l√Ω Ma Tr·∫≠n ƒê·∫∑c T·∫£",
    layout="wide"
)

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

MODEL_NAME = "gpt-4.1"

# =========================
# HELPER: READ FILE
# =========================
def read_pdf(file):
    text = ""
    with pdfplumber.open(file) as pdf:
        for i, page in enumerate(pdf.pages):
            text += f"\n--- Page {i+1} ---\n"
            text += page.extract_text() or ""
    return text

def read_docx(file):
    doc = docx.Document(file)
    return "\n".join(p.text for p in doc.paragraphs)

def read_excel(file):
    df = pd.read_excel(file)
    return df.to_csv(index=False)

def extract_text(file):
    name = file.name.lower()
    if name.endswith(".pdf"):
        return read_pdf(file)
    elif name.endswith(".docx"):
        return read_docx(file)
    elif name.endswith(".xlsx") or name.endswith(".xls"):
        return read_excel(file)
    else:
        return file.read().decode("utf-8", errors="ignore")

# =========================
# UI ‚Äì HEADER
# =========================
st.markdown("""
# üß† **TR·ª¢ L√ç MA TR·∫¨N ƒê·∫∂C T·∫¢**
_H·ªó tr·ª£ x√¢y d·ª±ng b·∫£ng ƒë·∫∑c t·∫£ ƒë·ªÅ ki·ªÉm tra ‚Äì chu·∫©n kh·∫£o th√≠_
""")

# =========================
# SECTION 1 ‚Äì DATA
# =========================
st.header("‚ë† D·ªØ li·ªáu tham chi·∫øu")

ref_files = st.file_uploader(
    "Upload t√†i li·ªáu (PDF / Word / Excel / Text)",
    type=["pdf", "docx", "xlsx", "xls", "txt", "csv"],
    accept_multiple_files=True
)

ref_text = st.text_area(
    "Ho·∫∑c d√°n n·ªôi dung tr·ª±c ti·∫øp",
    height=200
)

reference_contents = []

if ref_files:
    with st.spinner("ƒêang ƒë·ªçc file..."):
        for f in ref_files:
            try:
                reference_contents.append(
                    f"\n=== FILE: {f.name} ===\n" + extract_text(f)
                )
            except Exception as e:
                st.error(f"L·ªói ƒë·ªçc {f.name}: {e}")

# =========================
# SECTION 2 ‚Äì TEMPLATE
# =========================
st.header("‚ë° Khung ma tr·∫≠n m·∫´u")

template_file = st.file_uploader(
    "Upload file m·∫´u",
    type=["pdf", "docx", "xlsx", "xls", "txt", "csv"],
    accept_multiple_files=False
)

default_template = (
    "STT, N·ªôi dung ki·∫øn th·ª©c, ƒê∆°n v·ªã ki·∫øn th·ª©c, "
    "Chu·∫©n c·∫ßn ƒë√°nh gi√°, Nh·∫≠n bi·∫øt, Th√¥ng hi·ªÉu, "
    "V·∫≠n d·ª•ng, V·∫≠n d·ª•ng cao, T·ªïng s·ªë c√¢u, Ghi ch√∫"
)

template_text = st.text_area(
    "Khung c·ªôt ma tr·∫≠n",
    value=default_template,
    height=150
)

if template_file:
    with st.spinner("ƒêang ƒë·ªçc file m·∫´u..."):
        template_text += "\n\n" + extract_text(template_file)

# =========================
# SECTION 3 ‚Äì GENERATE
# =========================
st.header("‚ë¢ T·∫°o ma tr·∫≠n b·∫±ng AI")

if st.button("üöÄ T·∫†O MA TR·∫¨N ƒê·∫∂C T·∫¢", use_container_width=True):

    if not reference_contents and not ref_text.strip():
        st.error("‚ùå Ch∆∞a c√≥ d·ªØ li·ªáu tham chi·∫øu")
        st.stop()

    with st.spinner("GPT-4.1 ƒëang ph√¢n t√≠ch v√† x√¢y d·ª±ng ma tr·∫≠n..."):

        system_prompt = """
B·∫°n l√† CHUY√äN GIA KH·∫¢O TH√ç.

NHI·ªÜM V·ª§:
- Ph√¢n t√≠ch d·ªØ li·ªáu m√¥n h·ªçc
- T·∫°o B·∫¢NG MA TR·∫¨N ƒê·∫∂C T·∫¢

‚ö†Ô∏è QUY T·∫ÆC B·∫ÆT BU·ªòC:
1. Ch·ªâ tr·∫£ v·ªÅ JSON
2. Kh√¥ng markdown
3. Kh√¥ng gi·∫£i th√≠ch
4. T·∫§T C·∫¢ gi√° tr·ªã trong rows PH·∫¢I L√Ä STRING
5. Kh√¥ng number, kh√¥ng null
"""

        user_prompt = f"""
=== KHUNG MA TR·∫¨N ===
{template_text}

=== D·ªÆ LI·ªÜU THAM CHI·∫æU ===
{ref_text}

{"".join(reference_contents)}
"""

        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "matrix_spec",
                    "schema": {
                        "type": "object",
                        "properties": {
                            "headers": {
                                "type": "array",
                                "items": {"type": "string"}
                            },
                            "rows": {
                                "type": "array",
                                "items": {
                                    "type": "array",
                                    "items": {"type": "string"}
                                }
                            }
                        },
                        "required": ["headers", "rows"]
                    }
                }
            },
            temperature=0.2
        )

        try:
            result = json.loads(response.choices[0].message.content)
            df = pd.DataFrame(result["rows"], columns=result["headers"])

            st.success("‚úÖ T·∫°o ma tr·∫≠n th√†nh c√¥ng")
            st.dataframe(df, use_container_width=True)

            csv = df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "‚¨áÔ∏è T·∫£i file CSV",
                csv,
                "Ma_Tran_Dac_Ta.csv",
                "text/csv"
            )

        except Exception as e:
            st.error("‚ùå GPT-4.1 tr·∫£ d·ªØ li·ªáu l·ªói")
            st.code(response.choices[0].message.content)
