import streamlit as st
import pandas as pd
import pdfplumber
import docx
import os
import json
from dotenv import load_dotenv
from openai import OpenAI

# =============================
# STREAMLIT CONFIG
# =============================
st.set_page_config(
    page_title="Tr·ª£ l√Ω Ma Tr·∫≠n ƒê·∫∑c T·∫£",
    layout="wide"
)

# =============================
# LOAD ENV
# =============================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    st.error("‚ùå Ch∆∞a c·∫•u h√¨nh OPENAI_API_KEY trong Secrets")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)
MODEL_NAME = "gpt-4.1"   # C√≥ th·ªÉ ƒë·ªïi sang gpt-4o-mini ƒë·ªÉ test

# =============================
# FILE READERS
# =============================
def read_pdf(file):
    text = ""
    with pdfplumber.open(file) as pdf:
        for i, page in enumerate(pdf.pages):
            text += f"\n--- Trang {i+1} ---\n"
            text += page.extract_text() or ""
    return text

def read_docx(file):
    doc = docx.Document(file)
    return "\n".join(p.text for p in doc.paragraphs)

def read_excel(file):
    df = pd.read_excel(file)
    return df.to_csv(index=False)

def extract_text(file):
    name = file.name.lower()
    if name.endswith(".pdf"):
        return read_pdf(file)
    if name.endswith(".docx"):
        return read_docx(file)
    if name.endswith(".xlsx") or name.endswith(".xls"):
        return read_excel(file)
    return file.read().decode("utf-8", errors="ignore")

# =============================
# UI ‚Äì HEADER
# =============================
st.markdown("""
# üß† **TR·ª¢ L√ç MA TR·∫¨N ƒê·∫∂C T·∫¢**
_H·ªó tr·ª£ x√¢y d·ª±ng b·∫£ng ƒë·∫∑c t·∫£ ƒë·ªÅ ki·ªÉm tra ‚Äì chu·∫©n kh·∫£o th√≠_
""")

# =============================
# SECTION 1 ‚Äì DATA
# =============================
st.header("‚ë† D·ªØ li·ªáu tham chi·∫øu")

ref_files = st.file_uploader(
    "Upload t√†i li·ªáu (PDF / Word / Excel / Text)",
    type=["pdf", "docx", "xlsx", "xls", "txt", "csv"],
    accept_multiple_files=True
)

ref_text = st.text_area(
    "Ho·∫∑c d√°n n·ªôi dung tr·ª±c ti·∫øp",
    height=200
)

reference_contents = []

if ref_files:
    with st.spinner("ƒêang ƒë·ªçc file..."):
        for f in ref_files:
            try:
                reference_contents.append(
                    f"\n=== FILE: {f.name} ===\n{extract_text(f)}"
                )
            except Exception as e:
                st.error(f"L·ªói ƒë·ªçc {f.name}: {e}")

# =============================
# SECTION 2 ‚Äì TEMPLATE
# =============================
st.header("‚ë° Khung ma tr·∫≠n m·∫´u")

default_template = (
    "STT, N·ªôi dung ki·∫øn th·ª©c, ƒê∆°n v·ªã ki·∫øn th·ª©c, "
    "Chu·∫©n c·∫ßn ƒë√°nh gi√°, Nh·∫≠n bi·∫øt, Th√¥ng hi·ªÉu, "
    "V·∫≠n d·ª•ng, V·∫≠n d·ª•ng cao, T·ªïng s·ªë c√¢u, Ghi ch√∫"
)

template_text = st.text_area(
    "Khung c·ªôt ma tr·∫≠n",
    value=default_template,
    height=150
)

# =============================
# SECTION 3 ‚Äì GENERATE
# =============================
st.header("‚ë¢ T·∫°o ma tr·∫≠n b·∫±ng AI")

if st.button("üöÄ T·∫†O MA TR·∫¨N ƒê·∫∂C T·∫¢", use_container_width=True):

    if not reference_contents and not ref_text.strip():
        st.error("‚ùå Ch∆∞a c√≥ d·ªØ li·ªáu tham chi·∫øu")
        st.stop()

    with st.spinner("GPT-4.1 ƒëang ph√¢n t√≠ch v√† t·∫°o ma tr·∫≠n..."):

        system_prompt = """
B·∫°n l√† CHUY√äN GIA KH·∫¢O TH√ç.

QUY T·∫ÆC B·∫ÆT BU·ªòC:
- Ch·ªâ tr·∫£ v·ªÅ JSON
- Kh√¥ng markdown
- Kh√¥ng gi·∫£i th√≠ch
- T·∫§T C·∫¢ gi√° tr·ªã trong rows PH·∫¢I L√Ä STRING
- Kh√¥ng number, kh√¥ng null
"""

        user_prompt = f"""
=== KHUNG MA TR·∫¨N ===
{template_text}

=== D·ªÆ LI·ªÜU THAM CHI·∫æU ===
{ref_text}

{"".join(reference_contents)}
"""

        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={
                    "type": "json_schema",
                    "json_schema": {
                        "name": "matrix_spec",
                        "schema": {
                            "type": "object",
                            "properties": {
                                "headers": {
                                    "type": "array",
                                    "items": {"type": "string"}
                                },
                                "rows": {
                                    "type": "array",
                                    "items": {
                                        "type": "array",
                                        "items": {"type": "string"}
                                    }
                                }
                            },
                            "required": ["headers", "rows"]
                        }
                    }
                },
                temperature=0.2
            )

            result = json.loads(response.choices[0].message.content)
            df = pd.DataFrame(result["rows"], columns=result["headers"])

            st.success("‚úÖ T·∫°o ma tr·∫≠n th√†nh c√¥ng")
            st.dataframe(df, use_container_width=True)

            csv = df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "‚¨áÔ∏è T·∫£i file CSV",
                csv,
                "Ma_Tran_Dac_Ta.csv",
                "text/csv"
            )

        except Exception as e:
            st.error("‚ùå L·ªói khi g·ªçi GPT-4.1")
            st.exception(e)
